This is a collection of documents related to evaluating machine learning models.

# Introduction
1. [[Evaluating ML models]]
2. [[Train - test split of a dataset]]
3. Techniques used for validating models:
	- [[Cross Validation]]
4. Evaluation metrics for classification models:
	- Accuracy - [[Accuracy of a ML model|link]]
	- Precision - [[Precision of a ML model|link]]
	- Recall - [[Recall of a ML model|link]]
	- F1 score - [[F1 score of a ML model|link]]
	- ROC-AUC - [[ROC-AUC for evaluating ML models|link]]
	- Confusion Matrix - [[Confusion matrix|link]]
5. Evaluation metrics for regression models:
	- RMSE (Root Mean Squared Error) - [[RMSE (Root Mean Squared Error) of a ML model|link]]
	- R^2 - [[R squared for evaluating a ML model|link]]