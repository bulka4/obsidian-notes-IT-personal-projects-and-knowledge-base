This is a collection of documents describing how different machine learning models work.

# Introduction
1. [[What is a Machine Learning model]]
2. [[Decision Tree]]
	1. [[Decision tree - Building]]
3. [[Random Forest]]
	1. [[Random Forest - Building]]
4. [[AdaBoost]]
5. [[Hierarchical clustering]]
6. [[K means clustering]]
7. [[K nearest neighbors (KNN)]]
8. [[Linear Regression]]
9. [[Logistic Regression]]
	1. [[Logistic Regression - Building]]
10. [[Naive Bayes]]
11. [[Neural Network]]
	1. Layers:
		1. [[Neural Network - Fully-connected (dense) layer]]
			1. [[Neural Network - Dense layer described mathematically]]
		2. [[Neural Network - Convolution layer]]
			1. [[Neural Network - Convolution layer described mathematically]]
		3. [[Neural Network - Recurrent layer]]
			1. [[Neural Network - LSTM layer]]
			2. [[Neural Network - GRU layer]]
		4. [[Neural Network - Pooling layer]]
		5. [[Neural Network - Attention layer]]
			1. [[Neural Network - Multi-Head Attention (MHA) layer]]
			2. [[Neural Network Attention layer - Masking]]
			3. [[Neural Network - Multi-Query Attention (MQA) layer]]
			4. [[Neural Network - Grouped-Query Attention (GQA) layer]]
			5. [[Neural Network - Sliding Window Attention layer]]
	2. Layers combinations:
		1. [[Neural Network - Convolution plus Attention layer]]
	3. [[Neural Network related concepts]]
		1. [[Backpropagation]]
			1. [[Backpropagation (Dense layers)]]
		2. [[Data patching]]
		3. [[Padding an input for a ML model]]
		4. [[Residual connection]]
		5. [[Neural Network - Layer Normalization]]
		6. [[Autoencoders]]
12. [[Transformer model]]
13. [[Graph Neural Network]]
# Archived notes
1. [[Transformer model (Archive)]]