This is a collection of documents related to training machine learning models.

# Introduction
1. [[Training machine learning models - Introduction]]
2. [[Overfitting and generalization]]
3. [[Bias and variance]]
4. [[Batching]]
	1. [[Continuous (dynamic) batching]]
5. Likelihood:
	1. [[Likelihood function]]
	2. [[Maximum Likelihood Estimation (MLE)]]
6. Divergence between probability distributions:
	1. [[Minimizing divergence between probability distributions]]
	2. [[KL Divergence]]
	3. [[Relation between KL Divergence and Cross-Entropy and Entropy]]
	4. [[Using KL Divergence for training models]]
7. Regularization:
	1. [[Regularization]]
	2. [[L2 Regularization (Ridge)]]
	3. [[L1 Regularization (Lasso)]]
	4. [[Elastic Net Regularization]]
8. MAP Estimation:
	1. [[MAP Estimation (Maximum A Posteriori)]]
	2. [[Relation between MAP and minimizing loss with regularization]]
9. Relation between regularization and Map Estimation:
	1. [[Relation of L1 and L2 regularizations to MAP]]
10. [[Reinforcement learning]]
11. Loss functions:
	1. [[Loss functions]]
	2. Cross-Entropy:
		1. [[Cross-Entropy]]
		2. [[Empirical approximation of Cross-Entropy]]
		3. [[Relation of Cross-Entropy to the Maximum Likelihood Estimation]]
		4. [[Cross-Entropy for classification]]
	3. MSE (Mean Squared Error):
		1. [[MSE (Mean Squared Error)]]
		2. [[MSE relation to MLE (Maximum Likelihood Estimation)]]
12. Gradient-based optimization:
	1. [[Gradient Descent - ML]]
	2. [[Adam optimizer]]
	3. Optimization stability:
		1. [[Vanishing - exploding gradients]]
		2. [[Gradient control]]
			1. [[Gradient control - Gradient clipping]]
			2. [[Gradient control - Gradient normalization]]
		3. [[Learning rate warmup]]
		4. [[Adaptive optimizers]]