Tags: [[__Machine_Learning]]

# Introduction
This document explains in more details assumptions about the dataset as described in those documents:
- Separate variables for features and target variables:
	- [[Dataset of observations of random variables X, Y - Variables per sample, feature and target variable]]
	- [[Dataset of observations of random variables X, Y - Variables per feature and target variable]]
- One variable representing both features and target variables:
	- [[Dataset of observations of random variable X - Variables per sample and variable]]
	- [[Dataset of observations of random variable X - Variables per variable]]

Below explanations refers to assumptions and notation in case when we have two random variables X and Y, but everything is analogic in case when we have a single random variable X.
# Random variable samples (copies)
When we have pairs of random variables $(X_i, Y_i)$, we can look at them as copies or samples of a common, generic random variables $(X, Y)$.

We can say that $X$ and $Y$ are unknown, true random variables which generated given dataset of observations ([[Dataset of observations of random variables X, Y - Variables per sample, feature and target variable|link]]), and $(X_i, Y_i)$ are their copies which generated each of sample from that dataset.
# Dataset as an event
The observed dataset $D = \{ (x_i, y_i) \}_{i=1}^n$ is treated as a single event generated by the random variables ([[Event generated by a random variable|link]]) $X_1, \ldots, X_n, Y_1, \ldots, Y_n$.

Formally, that is an observation of multiple random variables for a single outcome $\omega \in \Omega$ of an experiment:
$$
D(\omega) = ((X_1(\omega), Y_1(\omega)), \ldots, (X_n(\omega), Y_n(\omega))) \in 
\prod_{i=1}^n (\mathcal{X}_i \times \mathcal{Y}_i)
$$
for random variables
$$
\begin{align}
X_i: \Omega \rightarrow \mathcal{X}_i \\
Y_i: \Omega \rightarrow \mathcal{Y}_i
\end{align}
$$
# Dataset as a matrix
The entire dataset $D$ can be viewed as a matrix of random variables:
$$
\large
D(\omega) = (X(\omega), Y(\omega)) = 
\begin{bmatrix}
X_{11}(\omega) & \cdots & X_{1m}(\omega) & Y_{11}(\omega) & \cdots & Y_{1l}(\omega) \\
\vdots &  & \vdots & \vdots &  & \vdots & \\
X_{n1}(\omega) & \cdots & X_{nm}(\omega) & Y_{n1}(\omega) & \cdots & Y_{nl}(\omega) \\
\end{bmatrix}
= \text{observed dataset}
$$
# A single random variable
We can also use notation without $y_i$ and $Y_i$ if we don't need to distinguish features from target variables.

Then, we denote a dataset as $D = \{ (x_i) \}_{i=1}^n$, where $x_i$ are observations of a single, multivariate random variable $X_i$. 

#MachineLearning 