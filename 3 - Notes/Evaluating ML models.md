Tags: [[__Machine_Learning]]

# Introduction
Evaluating a model means calculating a metric which shows how effective model is on a new data which this model never saw during training.

Techniques used for validating models include:
- Cross Validation - [[Cross Validation|link]]
- Train-test split - [[Train - test split of a dataset|link]]

Evaluation metrics for classification models include:
- Accuracy - [[Accuracy of a ML model|link]]
- Precision - [[Precision of a ML model|link]]
- Recall - [[Recall of a ML model|link]]
- F1 score - [[F1 score of a ML model|link]]
- ROC-AUC - [[ROC-AUC for evaluating ML models|link]]
- Confusion Matrix - [[Confusion matrix|link]]

Evaluation metrics for regression models include:
- RMSE (Root Mean Squared Error) - [[RMSE (Root Mean Squared Error) of a ML model|link]]
- R^2 - [[R squared for evaluating a ML model|link]]

#MachineLearning 