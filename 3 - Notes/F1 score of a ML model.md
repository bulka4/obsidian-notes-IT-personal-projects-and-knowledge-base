Tags: [[__Machine_Learning]]

# Introduction
The F1 Score metric is a harmonic mean of precision and recall - it balances both of them.

Low value indicates that one of the values - precision or recall - is much smaller then the other one.

It is a good metric when we need both precision and recall to be good.

It is calculated using both Precision and Recall:
$$
\text{F1} = 2 * \frac{\text{Precision} * \text{Recall}}{\text{Precision} + \text{Recall}}
$$

#MachineLearning 