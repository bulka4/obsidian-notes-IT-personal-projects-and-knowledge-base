Tags: [[_Obsidian]]

# Notes to prepare next
1. (done) DeepSpeed MII
2. Pipeline for multiple models / multi-tenancy
3. Caching & streaming tokens
4. (done) Torch distributed (`torch.distributed.launch` / `torchrun` for training)
5. MPI Operator (general notes and use case for DeepSpeed)
6. RDMA / Infiniband
7. GPU node pools, taints, and tolerations  (Ensures DeepSpeed pods only land on GPU nodes)
8. Kubeflow Pipelines / Trainer
9. KServe and NVIDIA NIM
10. Prometheus + Grafana  (Track GPU utilization, memory, inference throughput)
11. DCGM / NVIDIA GPU Operator metrics (Node-level metrics for profiling)
12. Distributed training logs (DeepSpeed logging, NCCL debug logs, rank-specific logs)
13. 