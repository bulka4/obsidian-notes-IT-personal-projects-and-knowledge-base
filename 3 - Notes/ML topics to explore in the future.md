Tags: [[_Obsidian]]

# Topics for later future
## Evaluating models
- Likelihood-based evaluation
## Probabilistic modelling
- Posterior predictive distribution - Predictive uncertainty
- Hierarchical models - Multi-level parameter structures
## Optimization
- Convex vs non-convex optimization
- Second-order methods
- schedules
## Probabilistic Dependencies & Information
- Graphical models - Bayesian networks, Markov random fields
## Probability
- Bayesian inference
- Probabilistic graphical models
- Uncertainty estimation
## Statistics
- Estimators
- Bias/variance
- Sampling
- Law of large numbers
- Central limit theorem
- Overfitting / underfitting
- Hypothesis testing
## Information theory
- compression
- MDL (Minimum Description Length)
## Geometry
- Parameter space geometry
- Norms (L1, L2, etc.)
- Geometric constraints → regularization
- Distance metrics
- Manifolds (deep learning can be interpreted with differential geometry)
## Computational Learning Theory
- VC dimension
- Rademacher complexity
- PAC learning
- PAC-Bayes theory
- Bias–variance tradeoff
## Approximation Theory 
Shows what functions models can represent:
- Universal approximation theorem
- Basis expansions
- Fourier transforms
- Kernel methods
- Splines / wavelets
This explains **what models are capable of representing**.
## Statistical Mechanics
- Loss ↔ energy
- Temperature ↔ regularization strength
- Phase transitions in learning
- Connections to spin glasses
## Control Theory
- Feedback systems
- Stability
- Optimal control
## Game Theory
- GANs
- Multi-agent RL
- Nash equilibria

#Obsidian 