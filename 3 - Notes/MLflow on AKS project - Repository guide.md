Tags: [[_My_projects]]
#MyProjects 

# Introduction
Here is described how to use code from this repository.
## Satisfying prerequisites
Before we start using this code we need to satisfy prerequisites described in the 'Prerequisites' section further in this document.
## Creating Azure resources and generating a Dockerfile
We need to create a few resources in Azure:
- AKS
- Storage Account
- ACR

Also we need to generate a few files which content depends on the created Azure resources:
- Dockerfile:
    - Used to run a container with prepared environment to interact with AKS
    - Saved in the docker folder
- values.yaml x2:
    - Two values.yaml files used in Helm charts:
    - Saved in the mlflow_project and mlflow_setup folders in the docker > helm_charts folder.

In order to create all those resources and generate files we need to run the following commands in the terraform folder:
>- terraform init # only when running Terraform for the first time in this repository
>- terraform plan -out main.tfplan
>- terraform apply main.tfplan
## Run a Docker container for interacting with AKS
Now we need to build a Docker image and run a container using the Dockerfile generated by Terraform. We can do that using the following commands (run them in the 'docker' folder):
>docker build -t aks .  # Build the image
>docker run -it aks     # Run the container

After running the container, it will:
- Trigger the script for building and pushing to ACR Docker images
- Start a bash session

Thanks to the '-it' option we will get access to the container's bash session from our terminal.

This container will be used to interact with AKS. From inside of it we will perform actions described in the next steps in this guide:
- Deploy MLflow Tracking Server on AKS
- Run MLflow project
## Deploy MLflow resources on AKS
Now from inside of the container we can deploy the MLflow Tracking Server and all the resources needed for running the MLflow project using Helm.

We do this by running the following commands in the /root/k8s/helm_charts > mlflow_setup directory:
>helm dependency update                             # <- Install dependency chart, i.e. MySQL (backend store)
>helm install mlflow . -n mlflow --create-namespace # <- Install the chart  

More information about what resources we are deploying here can be found further in this document in the 'MLflow setup Helm chart' section.
## Accessing MLflow Tracking Server website
We need to get a public IP of the Kubernetes Service which our Tracking Server Deployment is using:
>kubectl -n mlflow get svc mlflow-service

There will be written 'EXTERNAL-IP' which is our needed public IP.

We can access MLflow Tracking Server website using this URL:
>Public-IP:5000
## Upload MLflow project files to File share
File share need to contain MLflow project files to run and it will be mounted to the Job running the project.

We need to follow those steps:
- Go to the Storage Account created by Terraform (by default it will be called 'mlflowartifactsbulka' in the 'data_engineering_apps' resource group.)
- Go to File shares
- Go to the 'mlflow-projects' File share (that's the default name used by the Terraform code)
- Click on the 'Browse' tab
- Create a new folder called 'mlflow_project'
- Upload to this folder files from the mlflow_project folder from this repo
## Run MLflow project
Now we can run the MLflow project using Helm. We need to run the below command in the /root/k8s/helm_charts > mlflow_project directory:
>helm install run1 . -n mlflow

This will create a Job and a Pod called 'run1-mlflow-project-job-xxx'.
## Confirm the project has been completed successfully
In order to confirm that our project has been completed successfully, we can check logs of the Pod created by the Job we deployed using the Helm chart.

That Pod will be called `run1-mlflow-project-job-xxx` and we can check its logs using this command:
>kubectl -n mlflow logs run1-mlflow-project-job-xxx

We should see in those logs information like this:  
![](images/image1.png)

Also on the MLflow Tracking Server website we should see our run:  
![](images/image2.png)
## Destroying Azure resources
Once we are done, then in order to destroy all the created resources in Azure we need to run the following commands:
>terraform plan -destroy -out main.destroy.tfplan
>terraform apply main.destroy.tfplan

**Notes:**  
Sometimes deleting resources using Terraform doesn't work. In that case it is the best to delete resource groups manually from Azure website.