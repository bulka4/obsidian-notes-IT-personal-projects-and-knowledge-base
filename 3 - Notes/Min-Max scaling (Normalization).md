Tags: [[__Machine_Learning]]

# Introduction
Min-Max scaling (Normalization) is a technique of feature scaling ([[Feature scaling|link]]).

It rescales values to a fixed range, usually [0, 1] or [-1, 1]:
$$
\large
x' = \frac{x - x_{\text{min}}} {x_{\text{max}} - x_{\text{min}}}
$$
# Properties
- Preserves the shape of the distribution
- Sensitive to outliers

#MachineLearning 