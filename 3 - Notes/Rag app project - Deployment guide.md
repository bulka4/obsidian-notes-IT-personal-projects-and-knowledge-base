Tags: [[_My_projects]]
#MyProjects 

# Introduction
This document describes how to deploy RAG app from this project - [[RAG app project|link]]. 
# Overview
For deploying this application there are 3 Helm charts running different services:
- Milvus database and Python script populating it with a sample data
- MCP server
- Ray cluster with the Ray Serve application running on it
	- The RayService CRD is used for that

This application can be deployed by following steps below:
- Run Terraform code to:
	- Create Azure resources (AKS, ACR, Service Principal)
	- Save on our computer following files:
		- Dockerfile - For building an image for interacting with Azure resources
		- Values.yaml files - Files for Helm charts
- Rung a container for interacting with AKS using the Dockerfiles prepared by Terraform. From inside of this container perform all the next steps.
- Build and push images to ACR using the bash script prepared in the container
- (Optional) To simplify code development, upload to Azure File share application's files which will be mounted to Kubernetes pods
	- Thanks to this we can make changes in code without rebuilding all the Docker images
	- To use mounting we need to enable it using proper parameters in Helm charts (it is enabled by default)
- Install Helm charts
# Details
In order to run the code from this repo we need to follow steps listed below.

Some of those steps are optional and they are useful only during code development. In those steps we have written ‘(Optional for development)’. Once we have code prepared and we want to start using it more, we don’t need to follow those steps.

Steps to run the code:
- Create Azure resources using Terraform
- Run Docker container for interacting with AKS
- Build and push images to ACR
- (Optional for development) Upload scripts to File share
- Deploy Helm charts on AKS
- Confirm that Rest API works

Each of those steps is explained in more detail below.
# Create Azure resources using Terraform
Run the below Terraform commands:
```
terraform init # only when running Terraform for the first time in this repository
terraform plan -out main.tfplan
terraform apply main.tfplan
```

This will create Azure resources:
- AKS – Kubernetes cluster
- ACR – Registry for storing Docker images
- Service Principal – For authentication when interacting with AKS and ACR

And save those files on our computer:
- interacting.aks.Dockerfile – Dockerfile for building an image for interacting with AKS and ACR.
- Values.yaml files for Helm charts saved in the helm_charts folder:
    - common
    - mcp_server
    - prepare_milvus_db
    - ray_serve_app
# Run Docker container for interacting with AKS
Now we need to build a Docker image and run a container for interacting with AKS. We will use for that the Dockerfile generated by Terraform. We can do that using the following commands (run them in the repository’s root folder):
```

docker build . -t aks -f interacting.aks.Dockerfile

docker run -it aks /bin/bash

```

After running the container, it will start a bash session and we will have access to it from our computer’s terminal.

This container will be used to interact with AKS. From inside of it, we will be pushing images to ACR and deploying Helm charts for our agent.
# Build and push images to ACR
Now from inside of the container for interacting with AKS we need to run the script:
>/root/apps/build_and_push.sh

It will build and push to ACR images we will be deploying on AKS.
# (Optional for development) Upload scripts to File share
During development of the code, it is useful to mount scripts we want to run to pods. Thanks to that, we can make changes in code and we don’t need to rebuild images which is very time consuming.

If we are using mounting (it is enabled by default), then we need to upload below scripts from the repo to File share:
- apps/mcp_server - Upload to the mcp_server folder in File share
- apps/prepare_milvus_db – Upload to the prepare_milvus_db folder in File share
- apps/ray_serve_app – Upload to the ray_serve_app folder in File share
# Deploy Helm charts on AKS
Now from inside of the container for interacting with AKS we will deploy all the Helm charts which will create on AKS resources needed to run our agent.

Deploying each Helm chart takes some time. We can check if all the Pods are running using the ‘kubectl -n rag get pods’ command.

When we deploy one Helm chart, we might need to wait until it is ready before we deploy the next one (the safest option).

We start with deploying the common chart which prepares resources needed for other charts:
```
cd /root/helm_charts/common
helm install common . -n rag --create-namespace
```

Then we deploy the Job running a Python script preparing sample data in Milvus db by running below commands:
```
cd /root/helm_charts/prepare_milvus_db
helm dependency update
helm install milvus . -n rag
```

Here it is important to use the ‘milvus’ as a release name since this determines name of the service used by Milvus, so that’s a DNS name of the Milvus server used for connecting to Milvus in other charts.

Then we deploy the MCP Server by running below commands:
```
cd /root/helm_charts/mcp_server
helm install mcp-server . -n rag
```

Here it also matters to use the ‘mcp-server’ as a release name, since the next chart with Ray Serve app will be connecting to the pod running MCP Server using its service.

Then we deploy the Ray Serve app with the agent by running below commands:
```
cd /root/helm_charts/ray_service
helm dependency update
helm install ray-service . -n rag
```
# Confirm that Rest API works
Once the Helm chart with Ray Serve app has been installed, we can try to make a request to it from our local computer (it can be done from the container for interacting with AKS):
>curl http://\<service-external-ip\>:8000/ask?query=Hello

Where \<service-external-ip\> is an external IP of the service linked to the Ray head pod. That service is called ‘rag-rayservice-head’ in our case.

This command should return an answer from the RAG workflow.

We can also connect to the Ray head pod using this command:
>kubectl -n rag exec -it \<ray-head-pod-name\> -- /bin/bash

And run there this command:
>python -c “import ray; ray.init(); from ray import serve; print(serve.status().applications)”

This will show us a status of our Ray Serve application. In the displayed content we should see messages ‘RUNNING’ and ‘HEALTHY’.